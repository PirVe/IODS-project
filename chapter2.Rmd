# Week 2: Regression and model validation 

<!-- *Describe the work you have done this week and summarize your learning.*

- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using.-->

```{r, echo=F, message=F, warning=F}
date()
if (!require("pacman")) install.packages("pacman") 
pacman::p_load(tidyverse, forcats, haven, janitor, psych, lm.beta, broom, writexl,sjstats, knitr, pwr, dplyr, GGally, ggplot2)
library(dplyr)
library(GGally)
library(ggplot2)
```



The data used in this task is a subset of Learning 2014 survey data, collected by Kimmo Vehkalahti for an international survey of Approaches to Learning, made possible by Teachers' Academy funding for Kimmo Vehkalahti in 2013-2015.
The purpose of this exercise is to fit a linear regression model to the dataframe and try out model validation.

## What's in the dataframe
<!--  Reading the data, looking at structure and checking that the dataframe is readable -->
```{r}
lrn2014 <- read.csv("C:/Users/35840/OneDrive - University of Helsinki/IODS/IODS-project/data/lrn2014.csv")
str(lrn2014)
head(lrn2014)
dim(lrn2014)
```

There are 166 observations of 7 variables in the dataframe. Variables used are gender ("gender"), age ("age"), attitude ("attitude"), deep questions ("deep"), strategic questions ("stra"), surface questions ("surf") and exam points ("points"). Deep, stra and surf are combined variables from several related questions in the survey, which were scaled by taking the mean, and attitude a sum of 10 questions, which was scaled by dividing by the sum of the questions to the original Likert scale of 1-5. Points values of 0 have been excluded from the dataframe.

<!-- step 1 completed -->
## Summary overview of the data
<!-- summary() works to present numerical variables, using table() to present gender which is a categorical variable -->
```{r}
summary(lrn2014)
table(lrn2014$gender)
```
 The respondents were at 17 to 55 years old, median age 25,5 years. 110 were female and 56 male. Points varied between 7 to 33.

<!-- creating a visual presentation of all variables and their relations to one another -->
```{r}
p <- ggpairs(lrn2014, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
p
```

From the graph we can see that all variables "attitude", "deep", "stra", "surf" and "points" are approximately normally distributed. There is a statistically significant correlation between attitude and points, and other interesting correlations seem to exist between male respondents' answers to surface and deep questions.

<!-- step 2 completed -->

## Creating a regression model
For closer inspection variables "age", "attitude" and "surf" were selected to explain the target variable "points"

<!-- my regression model and summary -->
```{r}
my_model <- lm(points ~ age + attitude + surf, data = lrn2014)
summary(my_model)
```
Alpha is appr. 16,86 points, and the greatest effect to the exam points has attitude, 3,42 points. Age does not predict points very well as the effect is negative, -0,09 points, and answers to surface level questions have slightly negative effect on exam points, -0.96. The p-value of attitude in relation to points is statistically significant, which can be interpreted to confirm that attitude actually impacts exam points.
To find a better fitting model, both age and surf were at a time removed from the model.

<!-- creating a second model with attitude and surf -->
```{r}
my_model2 <- lm(points ~ attitude + surf, data = lrn2014)
summary(my_model2)
```
<!--  trying out another model with age and attitude -->
```{r}
my_model3 <- lm(points ~ age + attitude, data = lrn2014)
summary(my_model3)
```
<!--  step 3 completed -->
In any of the three models, the Multiple R-squared is approximately 20 %, which is quite low, as only one fifth of the results can be explained by the regression model. However, the dataset is a subset to begin with, and the respondent students have a wide array of other factors impacting their exam points. In this light, the low R-squared is acceptable. 

<!-- step 4 completed -->

## Model diagnostics 
To visualize the model diagnostics, the model is presented by Residuals vs Fitted values, Normal QQ-plot and Residuals vs Leverage.

```{r}
par(mfrow = c(2,2))
plot(my_model, which = c(1, 2, 5))
```
In the Residuals vs. Fitted graph the variance of the residuals is reasonably constant, implying that the size of the errors should not depend on the explanatory variables. The Normal Q-Q plot confirms the assumption that the errors of the model are normally distributed. By observing the residuals vs. leverage plot, no single observation stands out, and the leverage seems regular. 

<!-- step 5 completed -->
